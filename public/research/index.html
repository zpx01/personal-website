<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Zeeshan Patel</title>
  
  <meta name="author" content="Jon Barron">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
	<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üåê</text></svg>">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Zeeshan Patel</name>
              </p>
              <p>I am an undergraduate student at UC Berkeley studying Computer Science and Statistics. My main research focus is in generative computer vision and AI generalization. Currently, I am an undergraduate researcher at <a href="https://bair.berkeley.edu/">Berkeley Artificial Intelligence Research (BAIR)</a>, and I am advised by PhD student <a href="https://yossigandelsman.github.io/">Yossi Gandelsman</a> and <a href="https://people.eecs.berkeley.edu/~efros/">Professor Alexei Efros</a>. I am also interning as a Deep Learning Algorithms Engineer <a href="https://nvidia.github.io/NeMo/">NVIDIA NeMo</a>. 
              </p>
              <p>
                I have also interned at <a href="https://machinelearning.apple.com/">Apple AI/ML</a> as a ML Engineer on the Information Intelligence team where I worked on foundation models. Previosuly, I have also interned at <a href="https://www.verkada.com/">Verkada</a> on the Special Projects team as a ML engineer. 
              </p>
              <p style="text-align:center">
                <a href="mailto:zeeshanp@berkeley.edu">Email</a> &nbsp/&nbsp
                <a href="https://github.com/zpx01/">Github</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/zeeshan.JPG"><img style="width:100%;max-width:100%" alt="profile photo" src="images/zeeshan.JPG" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research</heading>
              <p>
                I'm broadly interested in machine learning, computer vision, and NLP. Specifically, I'm interested in the mechanisitic interpretability of deep learning models and how to create AI systems that can generalize under distribution shifts. I'm also curious about the intersection of vision and language and how visual systems can leverage language to interact with humans.
              </p>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:collapse;margin-right:auto;margin-left:auto;table-layout:fixed;"><tbody>
          <tr>
            <td style="padding:15px;width:50%;vertical-align:top;">
              <div class="one" style="width:100%;text-align:center;">
                <img src='images/swag_inference.png' style="display:block; max-width:175px;margin-left:auto;margin-right:auto;">
              </div>
            </td>
            <td style="padding:15px;width:50%;vertical-align:top;">
              <a href="data/swag.pdf">
                <papertitle>SWAG: Storytelling With Action Guidance</papertitle>
              </a>
              <br>
              <a href="https://zeeshanp.me/research"><strong>Zeeshan Patel*</strong></a>,
              <a href="https://jonnypei.github.io/">Jonathan Pei*</a>, 
              <a href="https://www.linkedin.com/in/karim-el-refai/">Karim El-Refai*</a>,
              <a href="https://www.linkedin.com/in/tianleli/">Tianle Li</a>
              <br>
              <em>Under Review</em>, 2024
              <br>
              <p>
                We introduce Storytelling With Action Guidance (SWAG), a novel approach to storytelling with LLMs. Our approach reduces story writing to a search problem through a two-model feedback loop. SWAG can substantially outperform previous end-to-end story generation techniques when evaluated by GPT-4 and through human evaluation, and our SWAG pipeline using only open-source models surpasses GPT-3.5- Turbo.
              </p>
            </td>
          </tr>
          <tr>
            <td style="padding:15px;width:50%;vertical-align:top;">
              <div class="one" style="width:100%;text-align:center;">
                <img src='images/ttt_diagram_copy.png' style="display:block; max-width:350px;margin-left:auto;margin-right:auto;">
              </div>
            </td>
            <td style="padding:15px;width:50%;vertical-align:top;">
              <a href="data/ttt_sr.pdf">
                <papertitle>Test-Time Training for Image Superresolution</papertitle>
              </a>
              <br>
              <a href="https://zeeshanp.me/research"><strong>Zeeshan Patel*</strong></a>,
              <a href="https://yossigandelsman.github.io/">Yossi Gandelsman</a>
              <br>
              <em>Preprint</em>, 2023
              <br>
              <p>
                A self-supervised approach for fine-tuning image superresolution models to adapt to new test distributions on-the-fly.
              </p>
            </td>
          </tr>
        </tbody></table>        
      </td>
    </tr>
  </table>
</body>

</html>
