<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Zeeshan Patel</title>
  
  <meta name="author" content="Jon Barron">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
	<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üåê</text></svg>">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Zeeshan Patel</name>
              </p>
              <p>I am an undergraduate student at UC Berkeley studying Computer Science and Statistics. My main research focuses are in generative models and AI understanding. I am advised by <a href="https://people.eecs.berkeley.edu/~efros/">Professor Alexei Efros</a> and <a href="https://yossigandelsman.github.io/">Yossi Gandelsman</a> at <a href="https://bair.berkeley.edu/">Berkeley Artificial Intelligence Research (BAIR)</a>. 
              </p>
              <p>
                Currently, I am interning as a Deep Learning Algorithms Engineer at <a href="https://nvidia.github.io/NeMo/">NVIDIA NeMo</a>. Previously, I've interned as a ML Engineer at <a href="https://machinelearning.apple.com/">Apple AI/ML</a> within the Information Intelligence team, focusing on foundation models, and at <a href="https://www.verkada.com/">Verkada</a> as a ML Engineer on the Special Projects team.
              </p>
              <p style="text-align:center">
                <a href="mailto:zeeshanp@berkeley.edu">Email</a> &nbsp/&nbsp
                <a href="https://github.com/zpx01/">Github</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/zeeshan.JPG"><img style="width:100%;max-width:100%" alt="profile photo" src="images/zeeshan.JPG" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research</heading>
              <p>
                I'm broadly interested in machine learning, computer vision, and generative AI. Specifically, I'm interested in the mechanisitic interpretability of deep learning models and how to create AI systems that can generalize under distribution shifts. I'm also curious about the intersection of vision and language and how visual systems can leverage language to interact with humans.
              </p>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:collapse;margin-right:auto;margin-left:auto;table-layout:fixed;"><tbody>
          <tr>
            <td style="padding:15px;width:50%;vertical-align:top;">
              <div class="one" style="width:100%;text-align:center;">
                <img src='images/swag_inference.png' style="display:block; max-width:175px;margin-left:auto;margin-right:auto;">
              </div>
            </td>
            <td style="padding:15px;width:50%;vertical-align:top;">
              <a href="data/swag.pdf">
                <papertitle>SWAG: Storytelling With Action Guidance</papertitle>
              </a>
              <br>
              <strong>Zeeshan Patel*</strong>,
              <a href="https://jonnypei.github.io/">Jonathan Pei*</a>, 
              <a href="https://www.linkedin.com/in/karim-el-refai/">Karim El-Refai*</a>,
              <a href="https://www.linkedin.com/in/tianleli/">Tianle Li</a>
              <br>
              <em>Under Review</em>, 2024
              <br>
              <a href="https://arxiv.org/abs/2402.03483">arXiv</a> / <a href="">code [coming soon]</a>
              <br>
              <p>
                We introduce Storytelling With Action Guidance (SWAG), a novel approach to storytelling with LLMs. Our approach reduces story writing to a search problem through a two-model feedback loop. SWAG can substantially outperform previous end-to-end story generation techniques when evaluated by GPT-4 and through human evaluation, and our SWAG pipeline using only open-source models surpasses GPT-3.5- Turbo.
              </p>
            </td>
          </tr>
          <tr>
            <td style="padding:15px;width:50%;vertical-align:top;">
              <div class="one" style="width:100%;text-align:center;">
                <img src='images/ttt_diagram_copy.png' style="display:block; max-width:350px;margin-left:auto;margin-right:auto;">
              </div>
            </td>
            <td style="padding:15px;width:50%;vertical-align:top;">
              <a href="data/ttt_sr.pdf">
                <papertitle>Test-Time Training for Image Superresolution</papertitle>
              </a>
              <br>
              <strong>Zeeshan Patel*</strong>,
              <a href="https://yossigandelsman.github.io/">Yossi Gandelsman</a>
              <br>
              <em>Preprint</em>, 2023
              <br>
              <p>
                A self-supervised approach for fine-tuning image superresolution models to adapt to new test distributions on-the-fly.
              </p>
            </td>
          </tr>
        </tbody></table>        
      </td>
    </tr>
  </table>
</body>

</html>
